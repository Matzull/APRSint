{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from interfaces.alchemy import AlchemyInterface\n",
    "import configparser\n",
    "from db.schema import StationLocation, Station, Messages\n",
    "from geopy.distance import great_circle\n",
    "from datetime import datetime\n",
    "import re\n",
    "from http.cookiejar import CookieJar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parser = configparser.ConfigParser()\n",
    "c_parser.read(\"../../config.ini\")\n",
    "config = {\"db\": dict(c_parser[\"db\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"EA3GKP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemy_interface = AlchemyInterface(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_station = alchemy_interface.select_obj(Station, **{\"station_id\": target})\n",
    "\n",
    "data_location = alchemy_interface.select_obj(\n",
    "    StationLocation,\n",
    "    [\"sync_id\", \"timestamp\", \"latitude\", \"longitude\", \"country\"],\n",
    "    df=True,\n",
    "    **{\"station\": target},\n",
    ")\n",
    "data_messages = alchemy_interface.select_obj(\n",
    "    Messages,\n",
    "    [\"sync_id\", \"dst_station\", \"path\", \"timestamp\", \"comment\"],\n",
    "    df=True,\n",
    "    **{\"src_station\": target},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_x</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>dst_station</th>\n",
       "      <th>path</th>\n",
       "      <th>timestamp_y</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2024-05-07 22:30:27.061016</td>\n",
       "      <td>41.37367</td>\n",
       "      <td>2.10450</td>\n",
       "      <td>Spain</td>\n",
       "      <td>APLG01</td>\n",
       "      <td>{TCPIP*,qAC,T2LAUSITZ}</td>\n",
       "      <td>2024-05-07 22:30:27.061016</td>\n",
       "      <td>Barcelona LoRa iGATE Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-05-07 22:30:27.776109</td>\n",
       "      <td>41.39567</td>\n",
       "      <td>2.13950</td>\n",
       "      <td>Spain</td>\n",
       "      <td>APDW15</td>\n",
       "      <td>{TCPIP*,qAC,T2SWEDEN}</td>\n",
       "      <td>2024-05-07 22:30:27.776109</td>\n",
       "      <td>---&gt;igate Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-05-07 22:30:35.212644</td>\n",
       "      <td>28.48233</td>\n",
       "      <td>-16.25633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APDW15</td>\n",
       "      <td>{TCPIP*,qAC,T2CSNGRAD}</td>\n",
       "      <td>2024-05-07 22:30:35.212644</td>\n",
       "      <td>---&gt;igate Santa Cruz de Tenerife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2024-05-07 22:30:35.865678</td>\n",
       "      <td>28.46617</td>\n",
       "      <td>-16.27167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APTW01</td>\n",
       "      <td>{WIDE3-3,qAO,EA3GKP-12}</td>\n",
       "      <td>2024-05-07 22:30:35.865678</td>\n",
       "      <td>Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2024-05-07 22:30:36.094951</td>\n",
       "      <td>41.33000</td>\n",
       "      <td>2.08933</td>\n",
       "      <td>Spain</td>\n",
       "      <td>APLG01</td>\n",
       "      <td>{TCPIP*,qAC,T2SPAIN}</td>\n",
       "      <td>2024-05-07 22:30:36.094951</td>\n",
       "      <td>Barcelona-El Prat LoRa iGATE Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2024-05-07 22:30:44.164192</td>\n",
       "      <td>28.46617</td>\n",
       "      <td>-16.27167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APTW01</td>\n",
       "      <td>{WIDE3-3,qAO,EA3GKP-12}</td>\n",
       "      <td>2024-05-07 22:30:44.164192</td>\n",
       "      <td>Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2024-05-07 22:30:44.247839</td>\n",
       "      <td>41.33000</td>\n",
       "      <td>2.08933</td>\n",
       "      <td>Spain</td>\n",
       "      <td>APLG01</td>\n",
       "      <td>{TCPIP*,qAC,T2UKRAINE}</td>\n",
       "      <td>2024-05-07 22:30:44.247839</td>\n",
       "      <td>Barcelona-El Prat LoRa iGATE Station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2024-05-07 22:30:53.160685</td>\n",
       "      <td>28.48233</td>\n",
       "      <td>-16.25633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APDW15</td>\n",
       "      <td>{TCPIP*,qAC,T2CSNGRAD}</td>\n",
       "      <td>2024-05-07 22:30:53.160685</td>\n",
       "      <td>---&gt;igate Santa Cruz de Tenerife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2024-05-07 22:30:53.212349</td>\n",
       "      <td>28.46617</td>\n",
       "      <td>-16.27167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APTW01</td>\n",
       "      <td>{WIDE3-3,qAO,EA3GKP-12}</td>\n",
       "      <td>2024-05-07 22:30:53.212349</td>\n",
       "      <td>Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2024-05-07 22:30:53.608758</td>\n",
       "      <td>41.33000</td>\n",
       "      <td>2.08933</td>\n",
       "      <td>Spain</td>\n",
       "      <td>APLG01</td>\n",
       "      <td>{TCPIP*,qAC,T2SPAIN}</td>\n",
       "      <td>2024-05-07 22:30:53.608758</td>\n",
       "      <td>Barcelona-El Prat LoRa iGATE Station</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp_x  latitude  longitude country dst_station  \\\n",
       "48 2024-05-07 22:30:27.061016  41.37367    2.10450   Spain      APLG01   \n",
       "49 2024-05-07 22:30:27.776109  41.39567    2.13950   Spain      APDW15   \n",
       "50 2024-05-07 22:30:35.212644  28.48233  -16.25633     NaN      APDW15   \n",
       "52 2024-05-07 22:30:35.865678  28.46617  -16.27167     NaN      APTW01   \n",
       "53 2024-05-07 22:30:36.094951  41.33000    2.08933   Spain      APLG01   \n",
       "55 2024-05-07 22:30:44.164192  28.46617  -16.27167     NaN      APTW01   \n",
       "56 2024-05-07 22:30:44.247839  41.33000    2.08933   Spain      APLG01   \n",
       "59 2024-05-07 22:30:53.160685  28.48233  -16.25633     NaN      APDW15   \n",
       "60 2024-05-07 22:30:53.212349  28.46617  -16.27167     NaN      APTW01   \n",
       "61 2024-05-07 22:30:53.608758  41.33000    2.08933   Spain      APLG01   \n",
       "\n",
       "                       path                timestamp_y  \\\n",
       "48   {TCPIP*,qAC,T2LAUSITZ} 2024-05-07 22:30:27.061016   \n",
       "49    {TCPIP*,qAC,T2SWEDEN} 2024-05-07 22:30:27.776109   \n",
       "50   {TCPIP*,qAC,T2CSNGRAD} 2024-05-07 22:30:35.212644   \n",
       "52  {WIDE3-3,qAO,EA3GKP-12} 2024-05-07 22:30:35.865678   \n",
       "53     {TCPIP*,qAC,T2SPAIN} 2024-05-07 22:30:36.094951   \n",
       "55  {WIDE3-3,qAO,EA3GKP-12} 2024-05-07 22:30:44.164192   \n",
       "56   {TCPIP*,qAC,T2UKRAINE} 2024-05-07 22:30:44.247839   \n",
       "59   {TCPIP*,qAC,T2CSNGRAD} 2024-05-07 22:30:53.160685   \n",
       "60  {WIDE3-3,qAO,EA3GKP-12} 2024-05-07 22:30:53.212349   \n",
       "61     {TCPIP*,qAC,T2SPAIN} 2024-05-07 22:30:53.608758   \n",
       "\n",
       "                                              comment  \n",
       "48                       Barcelona LoRa iGATE Station  \n",
       "49                                --->igate Barcelona  \n",
       "50                   --->igate Santa Cruz de Tenerife  \n",
       "52  Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...  \n",
       "53               Barcelona-El Prat LoRa iGATE Station  \n",
       "55  Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...  \n",
       "56               Barcelona-El Prat LoRa iGATE Station  \n",
       "59                   --->igate Santa Cruz de Tenerife  \n",
       "60  Meteo Santa Cruz de Tenerife 130m aSl (Ultimet...  \n",
       "61               Barcelona-El Prat LoRa iGATE Station  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(data_location, data_messages, on=\"sync_id\", how=\"right\").dropna(\n",
    "    subset=[\"latitude\", \"longitude\", \"timestamp_y\"]\n",
    ").sort_values(by=\"timestamp_x\").tail(10).drop(\"sync_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "packets = pd.merge(data_messages, data_location, on=\"sync_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print([(index < 3 or index > 9) if True else False for index in range(0, 9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemy_interface.search_text(table=Messages, language=\"English\", text=\"station\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRZ:\n",
    "    def __init__(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(\"../../config.ini\")\n",
    "        self.account_usage = {}\n",
    "        for section in config.sections():\n",
    "            if section.startswith(\"qrz_\"):\n",
    "                self.account_usage[\n",
    "                    (config[section][\"username\"], config[section][\"password\"])\n",
    "                ] = 0\n",
    "        if len(self.account_usage.items()) == 0:\n",
    "            raise ValueError(\"Config file does not contain any valid 'qrz' account\")\n",
    "        self.base_url = \"https://www.qrz.com/\"\n",
    "        jar = CookieJar()\n",
    "        self.session = requests.Session()\n",
    "        self.session.cookies = jar\n",
    "        self.is_logged = False\n",
    "\n",
    "    def prettify(self, text):\n",
    "        return text.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"#\", \"\")\n",
    "\n",
    "    def format_date(self, date, format):\n",
    "        date = datetime.strptime(date, format)\n",
    "        return date.isoformat()\n",
    "\n",
    "    def roll_accounts(self):\n",
    "        # choose a random username and password that has an account usage of less than 25\n",
    "        choices = [item[0] for item in self.account_usage.items() if item[1] < 25]\n",
    "        if not choices:\n",
    "            return None\n",
    "        login = choice(choices)\n",
    "        self.account_usage[login] += 1\n",
    "        return login\n",
    "\n",
    "    def login(self):\n",
    "        self.login_data = self.roll_accounts()\n",
    "        if not self.login_data:\n",
    "            return None\n",
    "        response = self.session.post(\n",
    "            \"https://www.qrz.com/login\",\n",
    "            data={\"username\": self.login_data[0], \"password\": self.login_data[1]},\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            self.is_logged = True\n",
    "        return True\n",
    "\n",
    "    def get_station(self, station):\n",
    "        if not self.login():\n",
    "            print(\"Daily limit reached for all accounts\")\n",
    "            return None\n",
    "        print(\"Requesting page\")\n",
    "        self.response = self.session.get(self.base_url + \"db/\" + station)\n",
    "        station_info = {}\n",
    "        if self.response.status_code != 200:\n",
    "            print(\"Could not fetch page: \", self.response.status_code)\n",
    "            return None\n",
    "        if \"Too many lookups\" in self.response.text:\n",
    "            print(\"Daily limit reached\")\n",
    "            self.account_usage[self.login_data] = 25\n",
    "            return self.get_station(station)\n",
    "\n",
    "        soup = BeautifulSoup(self.response.content, \"html.parser\")\n",
    "        station_info[\"name\"] = \" \".join(\n",
    "            soup.find_all(\"span\", {\"style\": \"color: black; font-weight: bold\"})[0]\n",
    "            .getText()\n",
    "            .split()\n",
    "        )\n",
    "\n",
    "        station_info[\"img\"] = (\n",
    "            soup.find(\"div\", id=\"calldata\").find(\"img\", id=\"mypic\").get(\"src\")\n",
    "        )\n",
    "        station_info[\"biography\"] = soup.find(\"divalue\", id=\"biodata\")\n",
    "        rows = []\n",
    "        for _, row in enumerate(soup.find(\"table\", id=\"detbox\").find_all(\"tr\")):\n",
    "            row_content = [el.text.strip() for el in row.find_all(\"td\")]\n",
    "            if row_content:\n",
    "                rows.append(row_content)\n",
    "        table_data = rows[1:]\n",
    "\n",
    "        geo = {}\n",
    "        for item in table_data:\n",
    "            if item[0].lower() in [\n",
    "                \"longitude\",\n",
    "                \"grid_square\",\n",
    "                \"geo source\",\n",
    "                \"latitude\",\n",
    "            ]:\n",
    "                geo[self.prettify(item[0])] = item[1]\n",
    "            elif item[0].lower() == \"othercallsigns\":\n",
    "                table_alias = soup.find(\"th\", string=\"Alias\").parent.parent.parent\n",
    "                aliases = {}\n",
    "                for row in table_alias.find_all(\"tr\"):\n",
    "                    if row.find_all(\"td\"):\n",
    "                        alias = row.find_all(\"td\")[0]\n",
    "                        aliases[alias.text] = (\n",
    "                            alias.find(\"a\")[\"href\"] if alias.find(\"a\") else None\n",
    "                        )\n",
    "                if aliases:\n",
    "                    station_info[\"alias\"] = aliases\n",
    "                continue\n",
    "            else:\n",
    "                if len(item) > 1:\n",
    "                    station_info[self.prettify(item[0])] = item[1]\n",
    "        if geo.get(\"longitude\") and geo.get(\"latitude\"):\n",
    "            geo[\"longitude\"] = float(geo[\"longitude\"].split()[0])\n",
    "            geo[\"latitude\"] = float(geo[\"latitude\"].split()[0])\n",
    "\n",
    "        geo[\"address\"] = \", \".join(\n",
    "            list(soup.find_all(\"p\", {\"class\": \"m0\"})[0].stripped_strings)[\n",
    "                4 if station_info.get(\"nickname\") else 2 :\n",
    "            ]\n",
    "        )\n",
    "        station_info[\"geo\"] = geo\n",
    "\n",
    "        for extra_field in [\"qsl_by_mail\", \"uses_lotw\", \"qsl_by_eqsl\"]:\n",
    "            if extra_field in station_info:\n",
    "                station_info[extra_field] = station_info[extra_field][:3].strip()\n",
    "\n",
    "        qrz_data = {}\n",
    "        for _, (field, value) in enumerate(station_info.items()):\n",
    "            try:\n",
    "                if not re.search(\n",
    "                    \"[a-zA-Z0-9]{1,3}[0-9][a-zA-Z0-9]{0,3}[a-zA-Z]\", field\n",
    "                ):\n",
    "                    qrz_data[field] = value\n",
    "            except Exception:\n",
    "                print(\"Error parsing field: \", field)\n",
    "\n",
    "        qrz_data[\"date_joined\"] = self.format_date(\n",
    "            qrz_data[\"date_joined\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        qrz_data[\"last_update\"] = self.format_date(\n",
    "            qrz_data[\"last_update\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        return qrz_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrz = QRZ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = qrz.get_station(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = station_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.pop(\"alias\")\n",
    "# data.pop(\"geo\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data).iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info = alchemy_interface.select_obj(\n",
    "    Station, \"*\", df=True, **{\"station_id\": target}\n",
    ")\n",
    "station_locations = alchemy_interface.select_obj(\n",
    "    StationLocation, \"*\", df=True, **{\"station\": target}\n",
    ")\n",
    "station_messages_src = alchemy_interface.select_obj(\n",
    "    Messages, \"*\", df=True, **{\"src_station\": target}\n",
    ")\n",
    "station_messages_dst = alchemy_interface.select_obj(\n",
    "    Messages, \"*\", df=True, **{\"dst_station\": target}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info.ssid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_timestamps(timestamps):\n",
    "    # Convertir los timestamps a un objeto DateTime\n",
    "    timestamps = pd.to_datetime(timestamps)\n",
    "\n",
    "    # Calcular la frecuencia de los timestamps\n",
    "    time_diffs = timestamps.diff()  # Diferencia entre cada timestamp\n",
    "    median_freq = time_diffs.median()\n",
    "    std_diff = time_diffs.std()\n",
    "\n",
    "    # Reajustar el índice de time_diffs para alinear con timestamps\n",
    "    time_diffs = time_diffs.reindex(timestamps.index, method=\"ffill\")\n",
    "\n",
    "    max_accepted_gap = median_freq + std_diff * 2\n",
    "    gaps = timestamps[time_diffs > max_accepted_gap]\n",
    "\n",
    "    # Información adicional\n",
    "    mean_freq = time_diffs.mean()\n",
    "    min_freq = time_diffs.min()\n",
    "    max_freq = time_diffs.max()\n",
    "    start_date = timestamps.min()\n",
    "    end_date = timestamps.max()\n",
    "    num_timestamps = len(timestamps)\n",
    "    total_duration = end_date - start_date\n",
    "\n",
    "    # Crear un diccionario con los resultados\n",
    "    analysis_results = {\n",
    "        \"mean_frequency\": mean_freq,\n",
    "        \"median_frequency\": median_freq,\n",
    "        \"min_frequency\": min_freq,\n",
    "        \"max_frequency\": max_freq,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"gaps\": gaps,\n",
    "        \"num_timestamps\": num_timestamps,\n",
    "        \"recorded_time\": total_duration,\n",
    "    }\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_timestamps(station_locations[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_locations(locations):\n",
    "    # Convertir las ubicaciones a un formato numpy para un fácil manejo\n",
    "    locations_np = np.array(locations)\n",
    "\n",
    "    # Calcular la distancia total y la distancia promedio entre puntos\n",
    "    distances = [\n",
    "        great_circle(locations_np[i], locations_np[i + 1]).kilometers\n",
    "        for i in range(len(locations_np) - 1)\n",
    "    ]\n",
    "    total_distance = sum(distances)\n",
    "    average_distance = np.mean(distances) if distances else 0\n",
    "    std_dev_distance = np.std(distances) if distances else 0\n",
    "\n",
    "    # Función para calcular el punto medio\n",
    "    def calculate_midpoint(locs):\n",
    "        lat = locs[:, 0]\n",
    "        lon = locs[:, 1]\n",
    "        return np.mean(lat), np.mean(lon)\n",
    "\n",
    "    # Calcular el punto medio\n",
    "    midpoint = calculate_midpoint(locations_np)\n",
    "\n",
    "    # Encontrar los extremos geográficos\n",
    "    northernmost = max(locations, key=lambda x: x[0])\n",
    "    southernmost = min(locations, key=lambda x: x[0])\n",
    "    easternmost = max(locations, key=lambda x: x[1])\n",
    "    westernmost = min(locations, key=lambda x: x[1])\n",
    "\n",
    "    # Calcular la distancia máxima desde el punto medio\n",
    "    max_distance_from_mid = max(\n",
    "        great_circle(midpoint, loc).kilometers for loc in locations\n",
    "    )\n",
    "\n",
    "    # Calcular el área aproximada cubierta por los puntos\n",
    "    latitudes = locations_np[:, 0]\n",
    "    longitudes = locations_np[:, 1]\n",
    "    approx_area = (\n",
    "        great_circle(\n",
    "            (latitudes.min(), longitudes.min()), (latitudes.min(), longitudes.max())\n",
    "        ).kilometers\n",
    "        * great_circle(\n",
    "            (latitudes.min(), longitudes.min()), (latitudes.max(), longitudes.min())\n",
    "        ).kilometers\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"locations\": locations,\n",
    "        \"total_distance_km\": total_distance,\n",
    "        \"average_distance_km\": average_distance,\n",
    "        \"std_dev_distance_km\": std_dev_distance,\n",
    "        \"midpoint\": midpoint,\n",
    "        \"northernmost\": northernmost,\n",
    "        \"southernmost\": southernmost,\n",
    "        \"easternmost\": easternmost,\n",
    "        \"westernmost\": westernmost,\n",
    "        \"max_distance_from_midpoint_km\": max_distance_from_mid,\n",
    "        \"approximate_area_sq_km\": approx_area,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = analyze_locations(station_locations[[\"latitude\", \"longitude\"]].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_map(analysis):\n",
    "    # Extraer información del análisis\n",
    "    midpoint = analysis[\"midpoint\"]\n",
    "    northernmost = analysis[\"northernmost\"]\n",
    "    southernmost = analysis[\"southernmost\"]\n",
    "    easternmost = analysis[\"easternmost\"]\n",
    "    westernmost = analysis[\"westernmost\"]\n",
    "\n",
    "    # Coordenadas para la bounding box\n",
    "    lon_box = [\n",
    "        westernmost[1],\n",
    "        easternmost[1],\n",
    "        easternmost[1],\n",
    "        westernmost[1],\n",
    "        westernmost[1],\n",
    "    ]\n",
    "    lat_box = [\n",
    "        northernmost[0],\n",
    "        northernmost[0],\n",
    "        southernmost[0],\n",
    "        southernmost[0],\n",
    "        northernmost[0],\n",
    "    ]\n",
    "\n",
    "    # Crear figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Añadir bounding box como un camino cerrado\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lon=lon_box,\n",
    "            lat=lat_box,\n",
    "            mode=\"lines\",\n",
    "            line=go.scattermapbox.Line(color=\"grey\"),\n",
    "            name=\"Bounding Box\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Añadir puntos extremos y punto medio\n",
    "    for point, name in zip(\n",
    "        [northernmost, southernmost, easternmost, westernmost, midpoint],\n",
    "        [\"Northernmost\", \"Southernmost\", \"Easternmost\", \"Westernmost\", \"Midpoint\"],\n",
    "    ):\n",
    "        fig.add_trace(\n",
    "            go.Scattermapbox(\n",
    "                lon=[point[1]],\n",
    "                lat=[point[0]],\n",
    "                mode=\"markers\",\n",
    "                marker=go.scattermapbox.Marker(size=5, color=\"black\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Establecer la vista inicial del mapa\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox={\"center\": {\"lon\": midpoint[1], \"lat\": midpoint[0]}, \"zoom\": 10},\n",
    "    )\n",
    "    lats, lons = zip(*analysis[\"locations\"])\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lon=lons,\n",
    "            lat=lats,\n",
    "            mode=\"markers+lines\",\n",
    "            line=go.scattermapbox.Line(color=\"black\"),\n",
    "            marker=go.scattermapbox.Marker(size=10, color=\"blue\"),\n",
    "            name=\"Bounding Box\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mostrar figura\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_loc_temporal(locations_timestamp):\n",
    "    # Convert column to datetime\n",
    "    locations_timestamp[\"timestamp\"].apply(lambda x: pd.to_datetime(x))\n",
    "    coordinates = list(\n",
    "        zip(locations_timestamp[\"latitude\"], locations_timestamp[\"longitude\"])\n",
    "    )\n",
    "    locations_timestamp = locations_timestamp.assign(coordinate=coordinates)\n",
    "    locations_timestamp[\"time_elapsed\"] = (\n",
    "        locations_timestamp.groupby(\"coordinate\")[\"timestamp\"]\n",
    "        .diff()\n",
    "        .fillna(pd.Timedelta(seconds=0))\n",
    "    )\n",
    "\n",
    "    # Calcular el tiempo total pasado en cada coordenada\n",
    "    total_time_elapsed = locations_timestamp.groupby(\"coordinate\")[\"time_elapsed\"].sum()\n",
    "\n",
    "    # Calcular la frecuencia de visitas a cada coordenada\n",
    "    visit_frequency = locations_timestamp[\"coordinate\"].value_counts()\n",
    "\n",
    "    # Calcular la fecha y hora de la primera y última visita a cada coordenada\n",
    "    first_visit = locations_timestamp.groupby(\"coordinate\")[\"timestamp\"].min()\n",
    "    last_visit = locations_timestamp.groupby(\"coordinate\")[\"timestamp\"].max()\n",
    "\n",
    "    # Calcular la duración total de la estancia en cada coordenada\n",
    "    total_stay_duration = last_visit - first_visit\n",
    "\n",
    "    # Crear un DataFrame con los resultados\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"total_time_elapsed\": total_time_elapsed,\n",
    "            \"visit_frequency\": visit_frequency,\n",
    "            \"first_visit\": first_visit,\n",
    "            \"last_visit\": last_visit,\n",
    "            \"total_stay_duration\": total_stay_duration,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_loc_temporal(station_locations[[\"latitude\", \"longitude\", \"timestamp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comment(comments):\n",
    "    # Calcular la frecuencia de comentarios distintos\n",
    "    unique_comments_freq = comments.value_counts()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\\b((https?|ftp):\\/\\/)?([\\w-]+(\\.[\\w-]+)+)([\\/\\w-]*)*(\\?\\w+=\\w+(&\\w+=\\w+)*)?\\b\"\n",
    "    )\n",
    "    urls = comments.apply(lambda x: pattern.search(x).group(0))\n",
    "    has_url = urls.apply(lambda x: x is not None)\n",
    "\n",
    "    results_list = []\n",
    "    for comment, freq, has_url_val, url in zip(\n",
    "        unique_comments_freq.index, unique_comments_freq.values, has_url, urls\n",
    "    ):\n",
    "        result_dict = {\n",
    "            \"Comment\": comment,\n",
    "            \"Freq\": freq,\n",
    "            \"has_url\": has_url_val,\n",
    "            \"URL\": url,\n",
    "        }\n",
    "        results_list.append(result_dict)\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_comment(station_messages_src[\"comment\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
