{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd())))\n",
    "from interfaces.alchemy import AlchemyInterface\n",
    "import configparser\n",
    "from db.schema import StationLocation, Station, Messages\n",
    "from geopy.distance import great_circle\n",
    "from datetime import datetime\n",
    "import re\n",
    "from http.cookiejar import CookieJar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_parser = configparser.ConfigParser()\n",
    "c_parser.read(\"../../config.ini\")\n",
    "config = {\"db\": dict(c_parser[\"db\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"W6HBR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alchemy_interface = AlchemyInterface(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRZ:\n",
    "    def __init__(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read(\"../../config.ini\")\n",
    "        self.account_usage = {}\n",
    "        for section in config.sections():\n",
    "            if section.startswith(\"qrz_\"):\n",
    "                self.account_usage[\n",
    "                    (config[section][\"username\"], config[section][\"password\"])\n",
    "                ] = 0\n",
    "        if len(self.account_usage.items()) == 0:\n",
    "            raise ValueError(\"Config file does not contain any valid 'qrz' account\")\n",
    "        self.base_url = \"https://www.qrz.com/\"\n",
    "        jar = CookieJar()\n",
    "        self.session = requests.Session()\n",
    "        self.session.cookies = jar\n",
    "        self.is_logged = False\n",
    "\n",
    "    def prettify(self, text):\n",
    "        return text.lower().replace(\" \", \"_\").replace(\"?\", \"\").replace(\"#\", \"\")\n",
    "\n",
    "    def format_date(self, date, format):\n",
    "        date = datetime.strptime(date, format)\n",
    "        return date.isoformat()\n",
    "\n",
    "    def roll_accounts(self):\n",
    "        # choose a random username and password that has an account usage of less than 25\n",
    "        choices = [item[0] for item in self.account_usage.items() if item[1] < 25]\n",
    "        if not choices:\n",
    "            return None\n",
    "        login = choice(choices)\n",
    "        self.account_usage[login] += 1\n",
    "        return login\n",
    "\n",
    "    def login(self):\n",
    "        self.login_data = self.roll_accounts()\n",
    "        if not self.login_data:\n",
    "            return None\n",
    "        response = self.session.post(\n",
    "            \"https://www.qrz.com/login\",\n",
    "            data={\"username\": self.login_data[0], \"password\": self.login_data[1]},\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            self.is_logged = True\n",
    "        return True\n",
    "\n",
    "    def get_station(self, station):\n",
    "        if not self.login():\n",
    "            print(\"Daily limit reached for all accounts\")\n",
    "            return None\n",
    "        print(\"Requesting page\")\n",
    "        self.response = self.session.get(self.base_url + \"db/\" + station)\n",
    "        station_info = {}\n",
    "        if self.response.status_code != 200:\n",
    "            print(\"Could not fetch page: \", self.response.status_code)\n",
    "            return None\n",
    "        if \"Too many lookups\" in self.response.text:\n",
    "            print(\"Daily limit reached\")\n",
    "            self.account_usage[self.login_data] = 25\n",
    "            return self.get_station(station)\n",
    "\n",
    "        soup = BeautifulSoup(self.response.content, \"html.parser\")\n",
    "        station_info[\"name\"] = \" \".join(\n",
    "            soup.find_all(\"span\", {\"style\": \"color: black; font-weight: bold\"})[0]\n",
    "            .getText()\n",
    "            .split()\n",
    "        )\n",
    "\n",
    "        station_info[\"img\"] = (\n",
    "            soup.find(\"div\", id=\"calldata\").find(\"img\", id=\"mypic\").get(\"src\")\n",
    "        )\n",
    "        station_info[\"biography\"] = soup.find(\"divalue\", id=\"biodata\")\n",
    "        rows = []\n",
    "        for _, row in enumerate(soup.find(\"table\", id=\"detbox\").find_all(\"tr\")):\n",
    "            row_content = [el.text.strip() for el in row.find_all(\"td\")]\n",
    "            if row_content:\n",
    "                rows.append(row_content)\n",
    "        table_data = rows[1:]\n",
    "\n",
    "        geo = {}\n",
    "        for item in table_data:\n",
    "            if item[0].lower() in [\n",
    "                \"longitude\",\n",
    "                \"grid_square\",\n",
    "                \"geo source\",\n",
    "                \"latitude\",\n",
    "            ]:\n",
    "                geo[self.prettify(item[0])] = item[1]\n",
    "            elif item[0].lower() == \"othercallsigns\":\n",
    "                table_alias = soup.find(\"th\", string=\"Alias\").parent.parent.parent\n",
    "                aliases = {}\n",
    "                for row in table_alias.find_all(\"tr\"):\n",
    "                    if row.find_all(\"td\"):\n",
    "                        alias = row.find_all(\"td\")[0]\n",
    "                        aliases[alias.text] = (\n",
    "                            alias.find(\"a\")[\"href\"] if alias.find(\"a\") else None\n",
    "                        )\n",
    "                if aliases:\n",
    "                    station_info[\"alias\"] = aliases\n",
    "                continue\n",
    "            else:\n",
    "                if len(item) > 1:\n",
    "                    station_info[self.prettify(item[0])] = item[1]\n",
    "        if geo.get(\"longitude\") and geo.get(\"latitude\"):\n",
    "            geo[\"longitude\"] = float(geo[\"longitude\"].split()[0])\n",
    "            geo[\"latitude\"] = float(geo[\"latitude\"].split()[0])\n",
    "\n",
    "        geo[\"address\"] = \", \".join(\n",
    "            list(soup.find_all(\"p\", {\"class\": \"m0\"})[0].stripped_strings)[\n",
    "                4 if station_info.get(\"nickname\") else 2 :\n",
    "            ]\n",
    "        )\n",
    "        station_info[\"geo\"] = geo\n",
    "\n",
    "        for extra_field in [\"qsl_by_mail\", \"uses_lotw\", \"qsl_by_eqsl\"]:\n",
    "            if extra_field in station_info:\n",
    "                station_info[extra_field] = station_info[extra_field][:3].strip()\n",
    "\n",
    "        qrz_data = {}\n",
    "        for _, (field, value) in enumerate(station_info.items()):\n",
    "            try:\n",
    "                if not re.search(\n",
    "                    \"[a-zA-Z0-9]{1,3}[0-9][a-zA-Z0-9]{0,3}[a-zA-Z]\", field\n",
    "                ):\n",
    "                    qrz_data[field] = value\n",
    "            except Exception:\n",
    "                print(\"Error parsing field: \", field)\n",
    "\n",
    "        qrz_data[\"date_joined\"] = self.format_date(\n",
    "            qrz_data[\"date_joined\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "        qrz_data[\"last_update\"] = self.format_date(\n",
    "            qrz_data[\"last_update\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        return qrz_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrz = QRZ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting page\n"
     ]
    }
   ],
   "source": [
    "station_data = qrz.get_station(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = station_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'HB Radio Club',\n",
       " 'img': 'https://cdn-bio.qrz.com/r/w6hbr/HBRACES_Logo2.png?p=419ad48a3141c06b1bc70b63c6483539',\n",
       " 'biography': None,\n",
       " 'lookups': '809 (1442)',\n",
       " 'qrz_record': '2245211',\n",
       " 'qrz_admin': 'WB6OZD',\n",
       " 'date_joined': '2017-04-16T01:10:57',\n",
       " 'last_update': '2024-03-19T13:30:04',\n",
       " 'class': 'Club  Codes: HVBF',\n",
       " 'trustee': 'Jon Welfringer - WB6OZD',\n",
       " 'effective': '2018-12-07',\n",
       " 'expires': '2028-12-07',\n",
       " 'grid_square': 'DM03xr',\n",
       " 'us_state': 'California',\n",
       " 'us_county': 'Orange',\n",
       " 'sunrise': '13:27:56 UTC',\n",
       " 'sunset': '02:19:04 UTC',\n",
       " 'cq_zone': '3',\n",
       " 'gmt_offset': '-8 hours',\n",
       " 'fcc_record_': '4107210',\n",
       " 'alias': {'KM6WYF': 'https://www.qrz.com/db/KM6WYF'},\n",
       " 'geo': {'geo_source': 'Geocoded Address',\n",
       "  'address': ', W6HBR, 16701 Roosevelt Lane, Huntington Beach, CA 92649, USA'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'HB Radio Club',\n",
       " 'img': 'https://cdn-bio.qrz.com/r/w6hbr/HBRACES_Logo2.png?p=419ad48a3141c06b1bc70b63c6483539',\n",
       " 'biography': None,\n",
       " 'lookups': '809 (1442)',\n",
       " 'qrz_record': '2245211',\n",
       " 'qrz_admin': 'WB6OZD',\n",
       " 'date_joined': '2017-04-16T01:10:57',\n",
       " 'last_update': '2024-03-19T13:30:04',\n",
       " 'class': 'Club  Codes: HVBF',\n",
       " 'trustee': 'Jon Welfringer - WB6OZD',\n",
       " 'effective': '2018-12-07',\n",
       " 'expires': '2028-12-07',\n",
       " 'grid_square': 'DM03xr',\n",
       " 'us_state': 'California',\n",
       " 'us_county': 'Orange',\n",
       " 'sunrise': '13:27:56 UTC',\n",
       " 'sunset': '02:19:04 UTC',\n",
       " 'cq_zone': '3',\n",
       " 'gmt_offset': '-8 hours',\n",
       " 'fcc_record_': '4107210'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.pop(\"alias\")\n",
    "# data.pop(\"geo\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_229151/3693427294.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tfg_env/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "pd.Series(data).iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_info = alchemy_interface.select_obj(\n",
    "    Station, \"*\", df=True, **{\"station_id\": target}\n",
    ")\n",
    "station_locations = alchemy_interface.select_obj(\n",
    "    StationLocation, \"*\", df=True, **{\"station\": target}\n",
    ")\n",
    "station_messages_src = alchemy_interface.select_obj(\n",
    "    Messages, \"*\", df=True, **{\"src_station\": target}\n",
    ")\n",
    "station_messages_dst = alchemy_interface.select_obj(\n",
    "    Messages, \"*\", df=True, **{\"dst_station\": target}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1\n",
       "unique    1\n",
       "top       2\n",
       "freq      1\n",
       "Name: ssid, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info.ssid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_timestamps(timestamps):\n",
    "    # Convertir los timestamps a un objeto DateTime\n",
    "    timestamps = pd.to_datetime(timestamps)\n",
    "\n",
    "    # Calcular la frecuencia de los timestamps\n",
    "    time_diffs = timestamps.diff()  # Diferencia entre cada timestamp\n",
    "    median_freq = time_diffs.median()\n",
    "    std_diff = time_diffs.std()\n",
    "\n",
    "    # Reajustar el índice de time_diffs para alinear con timestamps\n",
    "    time_diffs = time_diffs.reindex(timestamps.index, method=\"ffill\")\n",
    "\n",
    "    max_accepted_gap = median_freq + std_diff * 2\n",
    "    gaps = timestamps[time_diffs > max_accepted_gap]\n",
    "\n",
    "    # Información adicional\n",
    "    mean_freq = time_diffs.mean()\n",
    "    min_freq = time_diffs.min()\n",
    "    max_freq = time_diffs.max()\n",
    "    start_date = timestamps.min()\n",
    "    end_date = timestamps.max()\n",
    "    num_timestamps = len(timestamps)\n",
    "    total_duration = end_date - start_date\n",
    "\n",
    "    # Crear un diccionario con los resultados\n",
    "    analysis_results = {\n",
    "        \"mean_frequency\": mean_freq,\n",
    "        \"median_frequency\": median_freq,\n",
    "        \"min_frequency\": min_freq,\n",
    "        \"max_frequency\": max_freq,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"gaps\": gaps,\n",
    "        \"num_timestamps\": num_timestamps,\n",
    "        \"recorded_time\": total_duration,\n",
    "    }\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_timestamps(station_locations[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_locations(locations):\n",
    "    # Convertir las ubicaciones a un formato numpy para un fácil manejo\n",
    "    locations_np = np.array(locations)\n",
    "\n",
    "    # Calcular la distancia total y la distancia promedio entre puntos\n",
    "    distances = [\n",
    "        great_circle(locations_np[i], locations_np[i + 1]).kilometers\n",
    "        for i in range(len(locations_np) - 1)\n",
    "    ]\n",
    "    total_distance = sum(distances)\n",
    "    average_distance = np.mean(distances) if distances else 0\n",
    "    std_dev_distance = np.std(distances) if distances else 0\n",
    "\n",
    "    # Función para calcular el punto medio\n",
    "    def calculate_midpoint(locs):\n",
    "        lat = locs[:, 0]\n",
    "        lon = locs[:, 1]\n",
    "        return np.mean(lat), np.mean(lon)\n",
    "\n",
    "    # Calcular el punto medio\n",
    "    midpoint = calculate_midpoint(locations_np)\n",
    "\n",
    "    # Encontrar los extremos geográficos\n",
    "    northernmost = max(locations, key=lambda x: x[0])\n",
    "    southernmost = min(locations, key=lambda x: x[0])\n",
    "    easternmost = max(locations, key=lambda x: x[1])\n",
    "    westernmost = min(locations, key=lambda x: x[1])\n",
    "\n",
    "    # Calcular la distancia máxima desde el punto medio\n",
    "    max_distance_from_mid = max(\n",
    "        great_circle(midpoint, loc).kilometers for loc in locations\n",
    "    )\n",
    "\n",
    "    # Calcular el área aproximada cubierta por los puntos\n",
    "    latitudes = locations_np[:, 0]\n",
    "    longitudes = locations_np[:, 1]\n",
    "    approx_area = (\n",
    "        great_circle(\n",
    "            (latitudes.min(), longitudes.min()), (latitudes.min(), longitudes.max())\n",
    "        ).kilometers\n",
    "        * great_circle(\n",
    "            (latitudes.min(), longitudes.min()), (latitudes.max(), longitudes.min())\n",
    "        ).kilometers\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"locations\": locations,\n",
    "        \"total_distance_km\": total_distance,\n",
    "        \"average_distance_km\": average_distance,\n",
    "        \"std_dev_distance_km\": std_dev_distance,\n",
    "        \"midpoint\": midpoint,\n",
    "        \"northernmost\": northernmost,\n",
    "        \"southernmost\": southernmost,\n",
    "        \"easternmost\": easternmost,\n",
    "        \"westernmost\": westernmost,\n",
    "        \"max_distance_from_midpoint_km\": max_distance_from_mid,\n",
    "        \"approximate_area_sq_km\": approx_area,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = analyze_locations(station_locations[[\"latitude\", \"longitude\"]].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_map(analysis):\n",
    "    # Extraer información del análisis\n",
    "    midpoint = analysis[\"midpoint\"]\n",
    "    northernmost = analysis[\"northernmost\"]\n",
    "    southernmost = analysis[\"southernmost\"]\n",
    "    easternmost = analysis[\"easternmost\"]\n",
    "    westernmost = analysis[\"westernmost\"]\n",
    "\n",
    "    # Coordenadas para la bounding box\n",
    "    lon_box = [\n",
    "        westernmost[1],\n",
    "        easternmost[1],\n",
    "        easternmost[1],\n",
    "        westernmost[1],\n",
    "        westernmost[1],\n",
    "    ]\n",
    "    lat_box = [\n",
    "        northernmost[0],\n",
    "        northernmost[0],\n",
    "        southernmost[0],\n",
    "        southernmost[0],\n",
    "        northernmost[0],\n",
    "    ]\n",
    "\n",
    "    # Crear figura\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Añadir bounding box como un camino cerrado\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lon=lon_box,\n",
    "            lat=lat_box,\n",
    "            mode=\"lines\",\n",
    "            line=go.scattermapbox.Line(color=\"grey\"),\n",
    "            name=\"Bounding Box\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Añadir puntos extremos y punto medio\n",
    "    for point, name in zip(\n",
    "        [northernmost, southernmost, easternmost, westernmost, midpoint],\n",
    "        [\"Northernmost\", \"Southernmost\", \"Easternmost\", \"Westernmost\", \"Midpoint\"],\n",
    "    ):\n",
    "        fig.add_trace(\n",
    "            go.Scattermapbox(\n",
    "                lon=[point[1]],\n",
    "                lat=[point[0]],\n",
    "                mode=\"markers\",\n",
    "                marker=go.scattermapbox.Marker(size=5, color=\"black\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Establecer la vista inicial del mapa\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        mapbox={\"center\": {\"lon\": midpoint[1], \"lat\": midpoint[0]}, \"zoom\": 10},\n",
    "    )\n",
    "    lats, lons = zip(*analysis[\"locations\"])\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            lon=lons,\n",
    "            lat=lats,\n",
    "            mode=\"markers+lines\",\n",
    "            line=go.scattermapbox.Line(color=\"black\"),\n",
    "            marker=go.scattermapbox.Marker(size=10, color=\"blue\"),\n",
    "            name=\"Bounding Box\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mostrar figura\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_loc_temporal(locations_timestamp):\n",
    "    # Convert column to datetime\n",
    "    locations_timestamp[\"timestamp\"].apply(lambda x: pd.to_datetime(x))\n",
    "    coordinates = list(\n",
    "        zip(locations_timestamp[\"latitude\"], locations_timestamp[\"longitude\"])\n",
    "    )\n",
    "    locations_timestamp = locations_timestamp.assign(coordinate=coordinates)\n",
    "    locations_timestamp[\"time_elapsed\"] = (\n",
    "        locations_timestamp.groupby(\"coordinate\")[\"timestamp\"]\n",
    "        .diff()\n",
    "        .fillna(pd.Timedelta(seconds=0))\n",
    "    )\n",
    "\n",
    "    # Calcular el tiempo total pasado en cada coordenada\n",
    "    total_time_elapsed = locations_timestamp.groupby(\"coordinate\")[\"time_elapsed\"].sum()\n",
    "\n",
    "    # Calcular la frecuencia de visitas a cada coordenada\n",
    "    visit_frequency = locations_timestamp[\"coordinate\"].value_counts()\n",
    "\n",
    "    # Calcular la fecha y hora de la primera y última visita a cada coordenada\n",
    "    first_visit = locations_timestamp.groupby(\"coordinate\")[\"timestamp\"].min()\n",
    "    last_visit = locations_timestamp.groupby(\"coordinate\")[\"timestamp\"].max()\n",
    "\n",
    "    # Calcular la duración total de la estancia en cada coordenada\n",
    "    total_stay_duration = last_visit - first_visit\n",
    "\n",
    "    # Crear un DataFrame con los resultados\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"total_time_elapsed\": total_time_elapsed,\n",
    "            \"visit_frequency\": visit_frequency,\n",
    "            \"first_visit\": first_visit,\n",
    "            \"last_visit\": last_visit,\n",
    "            \"total_stay_duration\": total_stay_duration,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_loc_temporal(station_locations[[\"latitude\", \"longitude\", \"timestamp\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comment(comments):\n",
    "    # Calcular la frecuencia de comentarios distintos\n",
    "    unique_comments_freq = comments.value_counts()\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\\b((https?|ftp):\\/\\/)?([\\w-]+(\\.[\\w-]+)+)([\\/\\w-]*)*(\\?\\w+=\\w+(&\\w+=\\w+)*)?\\b\"\n",
    "    )\n",
    "    urls = comments.apply(lambda x: pattern.search(x).group(0))\n",
    "    has_url = urls.apply(lambda x: x is not None)\n",
    "\n",
    "    results_list = []\n",
    "    for comment, freq, has_url_val, url in zip(\n",
    "        unique_comments_freq.index, unique_comments_freq.values, has_url, urls\n",
    "    ):\n",
    "        result_dict = {\n",
    "            \"Comment\": comment,\n",
    "            \"Freq\": freq,\n",
    "            \"has_url\": has_url_val,\n",
    "            \"URL\": url,\n",
    "        }\n",
    "        results_list.append(result_dict)\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Comment': 'HBRACES.NET, AllStar 49372 (2m) & 49374 (70cm)',\n",
       "  'Freq': 29,\n",
       "  'has_url': True,\n",
       "  'URL': 'HBRACES.NET'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_comment(station_messages_src[\"comment\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
